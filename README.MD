# ğŸ” RAG PDF Assistant

A **Retrieval-Augmented Generation (RAG)** based PDF Assistant that allows users to:
- Upload a research paper or PDF,
- Automatically convert it to vector embeddings using `FAISS`,
- Ask questions in natural language,
- Get accurate, context-aware answers powered by **HuggingFace models**.

Built using:
- ğŸ¤— HuggingFace Transformers + LangChain
- ğŸ§  FAISS for Vector DB
- ğŸ“„ PyMuPDF (`fitz`) for PDF parsing
- ğŸ–¼ï¸ Gradio for UI



---


## ğŸ› ï¸ Features

âœ… Upload and process any academic or technical PDF  
âœ… Automatically splits text and stores embeddings using `FAISS`  
âœ… Asks questions in natural language (RAG-based answers)  
âœ… Clean Gradio UI  
âœ… Uses `google/flan-t5-base` for lightweight local inference  

---

## ğŸ“‚ Project Structure

```bash
â”œâ”€â”€ data/
â”‚   â””â”€â”€ your_uploaded.pdf #initially, to be used for testing purposes before the interface development
â”œâ”€â”€ vectorstore/
â”‚   â””â”€â”€ FAISS index
â”œâ”€â”€ rag.py              # Core logic for PDF parsing, embedding, and QA
â”œâ”€â”€ app.py              # Gradio UI app
â”œâ”€â”€ requirements.txt    # Dependencies
â””â”€â”€ README.md           # This file
```

<pre lang="markdown"> ## ğŸ§  Architecture ```mermaid graph TD A[PDF Upload] --> B[Extract Text with PyMuPDF] B --> C[Split Text into Chunks] C --> D[Convert Chunks to Embeddings via MiniLM] D --> E[Store in FAISS VectorDB] F[User Question] --> G[Retrieve Relevant Chunks] G --> H[FLAN-T5 Inference via LangChain] H --> I[Answer Returned] ``` </pre>